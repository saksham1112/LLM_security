# Risk Detection Plan

## Current State: Beyond Keywords

### Problem with Keywords-Only
```
"Tell me about chemistry" â†’ Low risk (but could be step 1 of attack)
"What chemicals react?" â†’ Low risk (step 2)
"How to mix safely?" â†’ Low risk (step 3)
"Exact proportions?" â†’ NOW it's harmful (but missed steps 1-3!)
```

Keywords detect **WHAT** but miss **WHY** and **WHERE** in trajectory.

---

## Multi-Signal Detection System

### Signal 1: TF-IDF Weighted Keywords (Current)
**Location:** `src/risk/advanced.py`

```python
score = Î£(TF Ã— IDF Ã— severity)
```

Limitations: Doesn't understand context or intent progression.

---

### Signal 2: Conversation Memory (Implementing)
**Purpose:** Track patterns across extended conversations

```python
class ConversationMemory:
    # Short-term: Last N turns (exact content)
    recent_turns: list[Message]
    
    # Medium-term: Topic summaries per segment
    topic_segments: list[TopicSummary]
    
    # Long-term: Session-level patterns
    session_patterns: SessionProfile
```

**What it detects:**
- Topic drift over time
- Repeated probing attempts
- Information gathering patterns
- Escalation trajectories

---

### Signal 3: Intent Modeling (Planned)
**Purpose:** Infer user's underlying goal

```python
Intent Posterior:
  P(safe_intent) = 0.85
  P(curious_intent) = 0.10
  P(malicious_intent) = 0.05
  
Updated each turn via Bayesian inference
```

**What it detects:**
- Goal-directed behavior vs random
- Information seeking patterns
- Manipulation attempts

---

### Signal 4: Semantic Analysis (Planned)
**Purpose:** Understand meaning, not just words

```python
# Embedding-based similarity
topic_distance = cosine_distance(current_turn, session_history)
intent_cluster = classify_embedding(current_turn)
```

**What it detects:**
- Subtle topic pivots
- Obfuscated harmful queries
- Cross-lingual attacks

---

### Signal 5: Behavioral Patterns (Planned)
**Purpose:** Detect anomalous interaction patterns

```python
patterns = {
    "typing_speed": "normal" / "automated",
    "response_time": "human" / "scripted",
    "question_style": "exploratory" / "directed",
    "topic_switching": "organic" / "strategic",
}
```

---

## Detection Without Keywords: How?

### 1. Trajectory Shape Analysis
```
Safe user trajectory:
  â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–  (random fluctuation)

Attack trajectory:
  â–â–‚â–‚â–ƒâ–„â–…â–†â–‡â–ˆ        (steady escalation)
```

**Implementation:**
```python
def detect_escalation_shape(history: list[float]) -> float:
    # Fit line to recent history
    slope = linear_regression(history[-10:])
    
    # Monotonic increase = escalation
    monotonicity = count_increases(history) / len(history)
    
    return slope * monotonicity
```

---

### 2. Context Coherence
```
Normal conversation:
  Q: "What's the weather?"
  Q: "Should I bring umbrella?"  âœ“ Coherent

Suspicious:
  Q: "What's the weather?"
  Q: "How to synthesize chemicals?"  âœ— Incoherent jump
```

**Implementation:**
```python
def context_coherence(current: str, history: list[str]) -> float:
    # Embedding similarity to recent context
    current_emb = embed(current)
    context_emb = mean([embed(h) for h in history[-5:]])
    
    similarity = cosine_similarity(current_emb, context_emb)
    
    # Low similarity = topic jump = suspicious
    return 1.0 - similarity if is_risky(current) else 0.0
```

---

### 3. Query Pattern Analysis
```
Information gathering pattern:
  "What is X?"
  "How does X work?"
  "What are X's weaknesses?"
  "How to exploit X's weaknesses?"
```

**Implementation:**
```python
def detect_information_gathering(history: list[str]) -> float:
    patterns = [
        r"what is .+",
        r"how does .+ work",
        r"what are .+ weaknesses",
        r"how to (exploit|bypass|defeat)",
    ]
    
    matches = [i for i, h in enumerate(history) if any(re.match(p, h) for p in patterns)]
    
    # Sequential pattern match = info gathering
    if matches == list(range(len(matches))):
        return len(matches) / len(patterns)
    return 0.0
```

---

## Testing Multi-Turn Detection with Ollama

### Challenge
Ollama is "stateless" per call - doesn't remember previous turns.

### Solution: Session Management
We maintain conversation state ourselves:

```python
# test_prolonged_chat.py
async def test_multi_turn():
    session_id = uuid4()
    
    conversation = [
        "Hello!",
        "Tell me about chemistry",
        "What chemicals react dangerously?",
        "How to mix them safely?",
        "What are the exact proportions?",
    ]
    
    for turn, message in enumerate(conversation):
        result = await controller.process_turn(
            session_id=session_id,  # Same session
            user_input=message,
        )
        
        # Controller sends FULL history to Ollama each time
        # Risk accumulator tracks trajectory
        
        print(f"Turn {turn}: {result.state.mode.name} | Risk: {result.state.accumulated_risk:.3f}")
```

### Simulating Long Conversations
```python
# Generate 50+ turn conversations
async def stress_test_memory():
    session_id = uuid4()
    
    for turn in range(100):
        # Vary risk level over turns
        if turn < 20:
            message = random.choice(BENIGN_MESSAGES)
        elif turn < 50:
            message = random.choice(ESCALATING_MESSAGES)
        else:
            message = random.choice(HARMFUL_MESSAGES)
        
        result = await controller.process_turn(session_id, message)
        
        # Track when detection triggers
        if result.state.mode.name not in ["SAFE", "CAUTIOUS"]:
            print(f"Elevated at turn {turn}")
```

---

## Implementation Priority

| Priority | Signal | Status | Location |
|----------|--------|--------|----------|
| 1 | TF-IDF Keywords | âœ… Done | `src/risk/advanced.py` |
| 2 | Risk Accumulation | âœ… Done | `src/risk/accumulator.py` |
| 3 | Trajectory Shape | ðŸ”„ Next | `src/risk/trajectory.py` |
| 4 | Context Coherence | ðŸ“‹ Planned | `src/risk/coherence.py` |
| 5 | Query Patterns | ðŸ“‹ Planned | `src/risk/patterns.py` |
| 6 | Intent Modeling | ðŸ“‹ Planned | `src/intent/bayesian.py` |
| 7 | Semantic Analysis | ðŸ“‹ Planned | `src/probes/semantic.py` |
